# ML-pipeline
üíñ Heart Disease Prediction Project
üìú Overview
This repository contains a machine learning project built in a Jupyter Notebook for predicting the likelihood of Heart Disease (AHD) in patients.

The project encompasses a complete Data Science lifecycle: from data loading and rigorous preprocessing to training, evaluating, and serializing machine learning models. The final model is then wrapped in a basic Flask API structure, ready for web deployment.

üéØ Project Goal
The primary objective is to:

Perform Exploratory Data Analysis (EDA) and Feature Engineering on patient health records.

Train and evaluate classification models, specifically Logistic Regression and a Random Forest Classifier, to predict the presence of Heart Disease (Yes/No).

Save the best-performing model (Random Forest Classifier) as final_model.pkl for future use and deployment.

Provide a basic Flask API to serve real-time predictions.

üì¶ Prerequisites and Setup
This project is written in Python and requires the following libraries.

Environment Setup
You can install the required packages using pip:

pip install pandas numpy matplotlib seaborn scikit-learn flask

üíñ Heart Disease Prediction Project
üìú Overview
This repository contains a machine learning project built in a Jupyter Notebook for predicting the likelihood of Heart Disease (AHD) in patients.

The project encompasses a complete Data Science lifecycle: from data loading and rigorous preprocessing to training, evaluating, and serializing machine learning models. The final model is then wrapped in a basic Flask API structure, ready for web deployment.

üéØ Project Goal
The primary objective is to:

Perform Exploratory Data Analysis (EDA) and Feature Engineering on patient health records.

Train and evaluate classification models, specifically Logistic Regression and a Random Forest Classifier, to predict the presence of Heart Disease (Yes/No).

Save the best-performing model (Random Forest Classifier) as final_model.pkl for future use and deployment.

Provide a basic Flask API to serve real-time predictions.

üì¶ Prerequisites and Setup
This project is written in Python and requires the following libraries.

Environment Setup
You can install the required packages using pip:

Bash

pip install pandas numpy matplotlib seaborn scikit-learn flask
Required Files
1.Untitled.ipynb: The main Jupyter Notebook containing all data cleaning, EDA, model training, evaluation, and the API code.

2.Heart.csv (Not provided, assumed to be in the working directory): The dataset containing patient health metrics used for training.

3.final_model.pkl (Generated by the notebook): The serialized trained Random Forest model.



üíñ Heart Disease Prediction Project
üìú Overview
This repository contains a machine learning project built in a Jupyter Notebook for predicting the likelihood of Heart Disease (AHD) in patients.

The project encompasses a complete Data Science lifecycle: from data loading and rigorous preprocessing to training, evaluating, and serializing machine learning models. The final model is then wrapped in a basic Flask API structure, ready for web deployment.

üéØ Project Goal
The primary objective is to:

Perform Exploratory Data Analysis (EDA) and Feature Engineering on patient health records.

Train and evaluate classification models, specifically Logistic Regression and a Random Forest Classifier, to predict the presence of Heart Disease (Yes/No).

Save the best-performing model (Random Forest Classifier) as final_model.pkl for future use and deployment.

Provide a basic Flask API to serve real-time predictions.

üì¶ Prerequisites and Setup
This project is written in Python and requires the following libraries.

Environment Setup
You can install the required packages using pip:

Bash

pip install pandas numpy matplotlib seaborn scikit-learn flask
Required Files
Untitled.ipynb: The main Jupyter Notebook containing all data cleaning, EDA, model training, evaluation, and the API code.

Heart.csv (Not provided, assumed to be in the working directory): The dataset containing patient health metrics used for training.

final_model.pkl (Generated by the notebook): The serialized trained Random Forest model.

üß† Methodology and Model Training
The Untitled.ipynb notebook follows a structured machine learning pipeline:

1. Data Preprocessing & EDA
Data Cleaning: Handles potential missing values and removes duplicate entries.

Outlier Handling: Outliers in numerical features are identified and treated using the Interquartile Range (IQR) method (1.5 * IQR).

Feature Engineering: A new categorical feature, AgeGroup, is created by binning the continuous Age column.

Categorical Encoding: Features like ChestPain, Thal, and AgeGroup are converted into numerical format using One-Hot Encoding (OHE).

Feature Scaling: Numerical features (Age, RestBP, Chol, MaxHR, Oldpeak) are scaled using StandardScaler to normalize their distribution.

2. Model Development
The processed data is split into an 80% training set and a 20% testing set (random_state=42).

Two models are trained:

Logistic Regression

Random Forest Classifier

3. Model Evaluation and Selection
Both models are evaluated on the test set, and the best one (Random Forest Classifier in this implementation) is selected based on key classification metrics: Accuracy, Precision, Recall, F1-Score, and ROC-AUC.

4. Model Serialization
The final, trained Random Forest Classifier is saved to the file final_model.pkl using Python's built-in pickle library.

üíñ Heart Disease Prediction Project
üìú Overview
This repository contains a machine learning project built in a Jupyter Notebook for predicting the likelihood of Heart Disease (AHD) in patients.

The project encompasses a complete Data Science lifecycle: from data loading and rigorous preprocessing to training, evaluating, and serializing machine learning models. The final model is then wrapped in a basic Flask API structure, ready for web deployment.

üéØ Project Goal
The primary objective is to:

Perform Exploratory Data Analysis (EDA) and Feature Engineering on patient health records.

Train and evaluate classification models, specifically Logistic Regression and a Random Forest Classifier, to predict the presence of Heart Disease (Yes/No).

Save the best-performing model (Random Forest Classifier) as final_model.pkl for future use and deployment.

Provide a basic Flask API to serve real-time predictions.

üì¶ Prerequisites and Setup
This project is written in Python and requires the following libraries.

Environment Setup
You can install the required packages using pip:

Bash

pip install pandas numpy matplotlib seaborn scikit-learn flask
Required Files
Untitled.ipynb: The main Jupyter Notebook containing all data cleaning, EDA, model training, evaluation, and the API code.

Heart.csv (Not provided, assumed to be in the working directory): The dataset containing patient health metrics used for training.

final_model.pkl (Generated by the notebook): The serialized trained Random Forest model.

üß† Methodology and Model Training
The Untitled.ipynb notebook follows a structured machine learning pipeline:

1. Data Preprocessing & EDA
Data Cleaning: Handles potential missing values and removes duplicate entries.

Outlier Handling: Outliers in numerical features are identified and treated using the Interquartile Range (IQR) method (1.5 * IQR).

Feature Engineering: A new categorical feature, AgeGroup, is created by binning the continuous Age column.

Categorical Encoding: Features like ChestPain, Thal, and AgeGroup are converted into numerical format using One-Hot Encoding (OHE).

Feature Scaling: Numerical features (Age, RestBP, Chol, MaxHR, Oldpeak) are scaled using StandardScaler to normalize their distribution.

2. Model Development
The processed data is split into an 80% training set and a 20% testing set (random_state=42).

Two models are trained:

Logistic Regression

Random Forest Classifier

3. Model Evaluation and Selection
Both models are evaluated on the test set, and the best one (Random Forest Classifier in this implementation) is selected based on key classification metrics: Accuracy, Precision, Recall, F1-Score, and ROC-AUC.

4. Model Serialization
The final, trained Random Forest Classifier is saved to the file final_model.pkl using Python's built-in pickle library.

‚òÅÔ∏è Deployment Guide (Flask API)
The final section of the notebook sets up a basic API for real-time predictions. This structure is meant to be saved as a separate Python file (e.g., app.py) for production deployment.

1. API Setup
The Flask server is initialized, and the final_model.pkl file is loaded into memory.

2. Running the Server
If you save the Flask code block as app.py, run the server from your terminal:

python app.py
# Server will start on http://127.0.0.1:5000/

3. Making a Prediction
The API exposes a /predict endpoint that requires a POST request with a JSON body containing the list of 14 features (which must be already scaled and one-hot encoded as per the notebook's preprocessing steps)

HTTP Method,Endpoint,Description
POST,/predict,Returns a prediction for the input features.

{
    "features": [0.35, 1.22, 0.45, -0.67, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
}

{
    "prediction": 1
}

1: Prediction is Heart Disease (Yes).

0: Prediction is No Heart Disease (No).
